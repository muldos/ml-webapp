name: "gh-mlops-webapp"
on: 
  schedule:
    - cron: "0 0 * * *"  
  workflow_dispatch:
jobs:
  build:
    runs-on: ubuntu-latest
    env:
      DOCKER_REPO: 'dro-oci-dev-virtual'
      IMAGE_NAME: 'mlops-demo'
      PYPI_REMOTE_REPO: 'dro-pypi-remote'
      JF_URL: https://${{ vars.JF_HOST }}/
      JF_PROJECT: ${{ vars.JF_PROJECT_KEY }}    
      JFROG_CLI_DEPENDENCIES_DIR: '/home/runner/work/ml-webapp/ml-webapp/.jfrog/dependencies'
    permissions:
      id-token: write
      contents: read
      actions: read 
      attestations: write    
      packages: write    
    # Here we install all the tools : docker buildx, QEMU, JDK 11, JFrog CLI
    steps:
      
      - name: Checkout
        uses: actions/checkout@v4
      - name: Setup JFrog CLI
        id: setup-cli
        uses: jfrog/setup-jfrog-cli@v4
        env:
          JF_URL: https://${{ vars.JF_HOST }}/
          JF_PROJECT: ${{ vars.JF_PROJECT_KEY }}
          PKG_VERSION: 1.${{ env.JFROG_CLI_BUILD_NUMBER }}.0
        with:
            oidc-provider-name: davidro-github-integration
            oidc-audience: davidro-github
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        # We audit and collect the dependencies outside of the dockerfile, for maximum traceability
      - name: Audit the dependencies
        run: |
          jf audit --pip --requirements-file=requirements.txt
      - name: Collect dependencies informations
        run: |
          jf pip-config --repo-resolve=$PYPI_REMOTE_REPO
          jf pip install -v --no-cache-dir -t ./pip-deps/ -r requirements.txt 
          jf rt bad --module ${{ env.IMAGE_NAME}}:${{ env.PKG_VERSION }} ${{ env.JFROG_CLI_BUILD_NAME }} ${{ env.JFROG_CLI_BUILD_NUMBER }} ./pip-deps/
      - name: Authenticate Docker
        uses: docker/login-action@v3
        with:
          registry: ${{ vars.JF_HOST }}
          username: ${{ steps.setup-cli.outputs.oidc-user }}
          password: ${{ steps.setup-cli.outputs.oidc-token }}         
      # just building arm64 as running of disk space on the public gh action runners
      - name: Build and push docker image
        env: 
          PKG_VERSION: 1.${{ env.JFROG_CLI_BUILD_NUMBER }}.0
          JF_ACCESS_TOKEN: ${{ steps.setup-cli.outputs.oidc-token }}  
        uses: docker/build-push-action@v6
        id: docker_build
        with:
          context: .
          #platforms: linux/amd64,linux/arm64
          platforms: linux/arm64
          provenance: true
          push: true
          build-args: |
            "jf_url=https://${{ vars.JF_HOST }}"
            "pypi_remote_repo=${{ env.PYPI_REMOTE_REPO }}"
            "BASE_IMAGE"=${{ vars.JF_HOST }}/${{ env.DOCKER_REPO }}/python:3.12.6
          secrets: |
            "pip-index-url=https://${{ steps.setup-cli.outputs.oidc-user }}:${{ steps.setup-cli.outputs.oidc-token }}@${{ vars.JF_HOST }}/artifactory/api/pypi/${{env.PYPI_REMOTE_REPO}}/simple"
            "jfrog-token=${{ env.JF_ACCESS_TOKEN }}"
            "HF_ENDPOINT=https://${{ vars.JF_HOST }}/artifactory/api/huggingfaceml/dro-mlops-hf-dev-local"
            "HF_TOKEN=${{ steps.setup-cli.outputs.oidc-token }}"
          tags: ${{ vars.JF_HOST }}/${{ env.DOCKER_REPO }}/${{ env.IMAGE_NAME}}:${{ env.PKG_VERSION }}
      - name: Docker info
        env: 
          PKG_VERSION: 1.${{ env.JFROG_CLI_BUILD_NUMBER }}.0
        run: |
          echo ${{ vars.JF_HOST }}/${{ env.DOCKER_REPO }}/${{ env.IMAGE_NAME}}:${{ env.PKG_VERSION }}@${{ steps.docker_build.outputs.digest }} > ./image-metadata.json
          jf rt bdc ${{ env.DOCKER_REPO }} --image-file ./image-metadata.json --build-name ${{ env.JFROG_CLI_BUILD_NAME }} --build-number ${{ env.JFROG_CLI_BUILD_NUMBER }}
      - name: Security assesments
        env: 
            PKG_VERSION: 1.${{ env.JFROG_CLI_BUILD_NUMBER }}.0
        run: |
          # Not enough space on public runners, would require a team / enterprise subscription or private runners
          # save some space on the runner before pulling the image 
          #docker buildx prune -f
          #sudo rm -rf "/usr/local/share/boost"
          # Xray build scan example
          #docker pull --platform=linux/arm64 ${{ vars.JF_HOST }}/${{ env.DOCKER_REPO }}/${{ env.IMAGE_NAME}}:${{ env.PKG_VERSION }}
          # remove docker scan for now, as default disk space on public runners is insufficient
          #jf docker scan ${{ vars.JF_HOST }}/${{ env.DOCKER_REPO }}/${{ env.IMAGE_NAME}}:${{ env.PKG_VERSION }} --severity='HIGH,CRITICAL' --vuln
          jf rt bp ${{ env.JFROG_CLI_BUILD_NAME }} ${{ env.JFROG_CLI_BUILD_NUMBER }}
          jf bs --fail=false --vuln ${{ env.JFROG_CLI_BUILD_NAME }} ${{ env.JFROG_CLI_BUILD_NUMBER }}